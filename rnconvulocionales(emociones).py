# -*- coding: utf-8 -*-
"""RNconvulocionales(emociones).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12vW8g4GbEXOGTsUOpGDQb3yYK5mJia4F
"""

from google.colab import files
uploaded = files.upload()

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# De la url del dataset se obtiene el nombre del programador y el nombre del dataset "halilsaglamlar/dog-cat"
!kaggle datasets download -d sanidhyak/human-face-emotions

!unzip human-face-emotions.zip

!ls

!ls data

import matplotlib.pyplot as plt
from PIL import Image

# Obtener imagenes
rutaImg = '/content/data/Happy/10-Habits-of-Happy-People-Seniors-Today.jpg'

# Abrir imagen
img = Image.open(rutaImg)
plt.imshow(img)
plt.axis('off')
plt.show()

# Graficar las imagenes
imgs5 = [
    '05-12-21-happy-people.jpg',
    '10-Habits-of-Happy-People-Seniors-Today.jpg',
    '110754-utyeqqosky-1547658396.jpeg',
    '1920px-face-smile.svg_.png.jpg',
    '220px-Happy_People_A_Year_in_the_Taiga_poster.jpg'
]
plt.figure(figsize = (15, 3))

for i, img5 in enumerate(imgs5):
  imgRoute = f'/content/data/Happy/{img5}'
  img = Image.open(imgRoute)

  # Configuración de subplot
  plt.subplot(1, 5, i + 1)
  plt.imshow(img)
  plt.axis("off")
  plt.title(img5)

plt.tight_layout()
plt.show()

# Crear red neuronal
import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import random

# Definición de directorios a cada carpeta de data
main = '/content/data'
happy = '/content/data/Happy'
angry = '/content/data/Angry'
sad = '/content/data/Sad'

# Arquitectura de la red
data = []
talla = 100
categorias = ['Angry', 'Happy', 'Sad']

for categoria in categorias:
  folder = os.path.join(main, categoria)
  label = categorias.index(categoria)

  for imagen in os.listdir(folder):

    #Excepto archivos gift
    if imagen.endswith('.gif'):
      continue

    imgPath = os.path.join(folder, imagen)
    imgArray = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)

  # Redimensionar la imagen
    try:
      imgArray = cv2.resize(imgArray, (talla, talla))
      data.append([imgArray, label])

    except Exception as e:
      print(e)

# Separar imagenes y etiquetas

xTrain = []
yTrain = []

for imgs, labels in data:
  xTrain.append(imgs)
  yTrain.append(labels)

# Normalizar los datos
xTrain = np.array(xTrain).reshape(-1, talla, talla, 1) / 255.0
yTrain = np.array(yTrain)

len(data)

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(xTrain, yTrain, test_size = 0.20, random_state = 0)

# Red neuronal
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

# Modelo
modelo = Sequential()

# Capa de entrada
modelo.add(Flatten(input_shape = (talla, talla, 1)))

# 1° capa oculta
modelo.add(Dense(256, activation = 'relu'))

# 2° capa oculpa
modelo.add(Dense(128, activation = 'swish'))

# 3° capa oculpa
modelo.add(Dense(64))
modelo.add(LeakyReLU(alpha = 0.01))

# Capa de salida
modelo.add(Dense(len(categorias), activation = 'softmax'))

# Compilar el modelo
modelo.compile(optimizer = Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# Early stoppings
earlyStop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)

# Entrenamiento
history = modelo.fit(xTrain, yTrain, epochs = 50, validation_data = (xTest, yTest), callbacks = [earlyStop], batch_size = 32)