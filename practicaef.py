# -*- coding: utf-8 -*-
"""PracticaEF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vGgzjd7nPoQWK7tejHm-W2O0T6tlmY78
"""

# REDES NEURONALES CONVOLUCIONALES (CNNs)

# Librerias
import matplotlib.pyplot as plt
from PIL import Image
import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import random
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

from google.colab import files
# uploaded = files.upload()

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# De la url del dataset se obtiene el nombre del programador y el nombre del dataset "halilsaglamlar/dog-cat"
!kaggle datasets download -d halilsaglamlar/dog-cat

# Descomprimir el archivo
# !unzip dog-cat.zip

# Obtener las imagenes
imgRoute = '/content/data/train/cat/cat.0.jpg'

# Abrir imagen
img = Image.open(imgRoute)

# Mostrar imagen
plt.imshow(img)
plt.axis('off')
plt.show()

# Mostrar las primeras 5 imagenes del folder
!ls /content/data/train/cat | head -5

# Guardar las imagenes en un array
imgs5 = [
    'cat.0.jpg',
    'cat.10000.jpg',
    'cat.10001.jpg',
    'cat.10002.jpg',
    'cat.10003.jpg'
]

# Definir el tamaño de las imagenes
plt.figure(figsize = (15, 3))

# Mostrar imagenes
for i, img5 in enumerate(imgs5):
  imgRoute = f'/content/data/train/cat/{img5}'
  img = Image.open(imgRoute)

  # Configuración de subplot
  plt.subplot(1, 5, i + 1)
  plt.imshow(img)
  plt.axis("off")
  plt.title(img5)

plt.tight_layout()
plt.show()

!ls /content/data/train/dog | head -5

# Definición de carpeta
main = '/content/data'
test = '/content/data/train'
train = '/content/data/train'
validation = '/content/data/validation'

# Preprocesamiento de datos
data = []
talla = 100
categorias = ['cat', 'dog']

for categoria in categorias:
  folder = os.path.join(train, categoria)
  label = categorias.index(categoria)

  for imagen in os.listdir(folder):

    #Excepto archivos gift
    if imagen.endswith('.gif'):
      continue

    imagenPath = os.path.join(folder, imagen)
    imagenArray = cv2.imread(imagenPath, cv2.IMREAD_GRAYSCALE)

    # Redimensionar la imagen
    try:
      imagenArray = cv2.resize(imagenArray, (talla, talla))
      data.append([imagenArray, label])

    except Exception as e:
      print(str(e))

# Separar imagenes y etiquetas
xTrain = []
yTrain = []

for imagenes, labels in data:
  xTrain.append(imagenes)
  yTrain.append(labels)

# Normalizar los datos
xTrain = np.array(xTrain).reshape(-1, talla, talla, 1)
yTrain = np.array(yTrain)

xTrain = xTrain / 255.0

# Entrenando la red neuronal
modelo = tf.keras.models.Sequential()
# Capa de entrada
modelo.add(tf.keras.layers.Flatten(input_shape = (talla, talla, 1)))
# Primera capa oculta
modelo.add(tf.keras.layers.Dense(256, activation = 'relu'))
# Segunda capa oculta
modelo.add(Dense(128, activation = 'swish'))
# Tercera capa de salida
modelo.add(Dense(64))
modelo.add(LeakyReLU(alpha = 0.01))
# Capa de salida
modelo.add(tf.keras.layers.Dense(2, activation = 'softmax'))
# Compilar el modelo
modelo.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')

# Early stoppings
earlyStop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)

# Entrenamiento
modelo.fit(xTrain, yTrain, epochs=20, validation_split = 0.2, callbacks=[earlyStop])

# Generar predicción
def predecirImg(rutaImg):
  imgPrueba = cv2.imread(rutaImg, cv2.IMREAD_GRAYSCALE)
  imgPrueba = cv2.resize(imgPrueba, (talla, talla))
  imgPrueba = np.array(imgPrueba).reshape(-1, talla, talla, 1)
  imgPrueba = imgPrueba / 255.0

  prediction = modelo.predict([imgPrueba])
  print('Probabilidad gato: ', prediction[0][0])
  print('Probabilidad perro: ', prediction[0][1])

routeNewImg = '/content/cat.jpeg'
predecirImg(routeNewImg)

from google.colab import files
import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import random
import matplotlib.pyplot as plt
from PIL import Image
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

# uploaded = files.upload()

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# De la url del dataset se obtiene el nombre del programador y el nombre del dataset "halilsaglamlar/dog-cat"
!kaggle datasets download -d sanidhyak/human-face-emotions

!unzip human-face-emotions.zip

# Obtener imagenes
rutaImg = '/content/data/Happy/10-Habits-of-Happy-People-Seniors-Today.jpg'

# Abrir imagen
img = Image.open(rutaImg)
plt.imshow(img)
plt.axis('off')
plt.show()

# Graficar las imagenes
imgs5 = [
    '05-12-21-happy-people.jpg',
    '10-Habits-of-Happy-People-Seniors-Today.jpg',
    '110754-utyeqqosky-1547658396.jpeg',
    '1920px-face-smile.svg_.png.jpg',
    '220px-Happy_People_A_Year_in_the_Taiga_poster.jpg'
]
plt.figure(figsize = (15, 3))

for i, img5 in enumerate(imgs5):
  imgRoute = f'/content/data/Happy/{img5}'
  img = Image.open(imgRoute)

  # Configuración de subplot
  plt.subplot(1, 5, i + 1)
  plt.imshow(img)
  plt.axis("off")
  plt.title(img5)

plt.tight_layout()
plt.show()

# Definición de directorios a cada carpeta de data
main = '/content/data'
happy = '/content/data/Happy'
angry = '/content/data/Angry'
sad = '/content/data/Sad'

# Arquitectura de la red
data = []
talla = 100
categorias = ['Angry', 'Happy', 'Sad']

for categoria in categorias:
  folder = os.path.join(main, categoria)
  label = categorias.index(categoria)

  for imagen in os.listdir(folder):

    #Excepto archivos gift
    if imagen.endswith('.gif'):
      continue

    imgPath = os.path.join(folder, imagen)
    imgArray = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)

  # Redimensionar la imagen
    try:
      imgArray = cv2.resize(imgArray, (talla, talla))
      data.append([imgArray, label])

    except Exception as e:
      print(e)

# Separar imagenes y etiquetas

xTrain = []
yTrain = []

for imgs, labels in data:
  xTrain.append(imgs)
  yTrain.append(labels)

# Normalizar los datos
xTrain = np.array(xTrain).reshape(-1, talla, talla, 1) / 255.0
yTrain = np.array(yTrain)

len(data)

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(xTrain, yTrain, test_size = 0.20, random_state = 0)

# Modelo
modelo = Sequential()

# Capa de entrada
modelo.add(Flatten(input_shape = (talla, talla, 1)))

# 1° capa oculta
modelo.add(Dense(256, activation = 'relu'))

# 2° capa oculpa
modelo.add(Dense(128, activation = 'swish'))

# 3° capa oculpa
modelo.add(Dense(64))
modelo.add(LeakyReLU(alpha = 0.01))

# Capa de salida
modelo.add(Dense(len(categorias), activation = 'softmax'))

# Compilar el modelo
modelo.compile(optimizer = Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# Early stoppings
earlyStop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)

# Entrenamiento
history = modelo.fit(xTrain, yTrain, epochs = 50, validation_data = (xTest, yTest), callbacks = [earlyStop], batch_size = 32)

# REDES NEURONALES RECURRENTES (RNNs)

# Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn .preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import yfinance as yf
from sklearn.utils import validation
from scipy.optimize import optimize

# Companies
tickers = ['AAPL', 'GOOGL', 'TSLA', 'MSFT']
allData = {ticker: yf.download(ticker, start = '2020-01-01', end = '2023-01-01') for ticker in tickers}

# Dataframe
df = pd.DataFrame({ticker: data['Close'] for ticker, data in allData.items()})
print(df.head())

# Data visualization
df.plot(figsize = (15, 7))
plt.title('Close Price 2020 - 2023')
plt.ylabel('Close Price')
plt.xlabel('Date')
plt.legend(tickers)
plt.grid(True)
plt.show

# Save data in csv
for ticker, data in allData.items():
  data.to_csv(f'{ticker}-2020-2023')

  # Scale data
scaler = MinMaxScaler(feature_range=(0, 1))
scaledData = scaler.fit_transform(data['Close'].values.reshape(-1, 1))

# Create sequences X, Y
X = []
Y = []

sequence = 60

for i in range(sequence, len(scaledData)):
    X.append(scaledData[i - sequence:i])
    Y.append(scaledData[i, 0])

X, Y = np.array(X), np.array(Y)

# Divide data
trainSize = int(0.8 * len(X))
Xtrain, Ytrain = X[:trainSize], Y[:trainSize]
Xtest, Ytest = X[trainSize:], Y[trainSize:]

Xtrain.shape, Xtest.shape

# Building LSTM model
model = Sequential()

# First layer
model.add(LSTM(units = 50, return_sequences = True, input_shape = (Xtrain.shape[1], 1)))
model.add(Dropout(0.20))

# Second layer
model.add(LSTM(units = 50, return_sequences = True))
model.add(Dropout(0.20))

# Third layer
model.add(LSTM(units = 50))
model.add(Dropout(0.20))

# Last layer
model.add(Dense(units = 1))

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Early Stopping
EarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
history = model.fit(Xtrain, Ytrain, epochs = 100, batch_size = 32, validation_data = (Xtest, Ytest), callbacks=[EarlyStop], verbose = 1)

# Loss function
loss = model.evaluate(Xtest, Ytest, verbose = 1)

# Price prediction
predictedPrices = model.predict(Xtest)
predictedPrices = scaler.inverse_transform(predictedPrices)

# AUTOENCODERS

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.datasets import mnist
from tensorflow.keras.callbacks import EarlyStopping

(Xtrain, _), (Xtest, _) = mnist.load_data()

Xtrain = Xtrain.astype('float32') / 255.0
Xtest = Xtest.astype('float32') / 255.

# Crear columna
Xtrain = Xtrain.reshape((len(Xtrain), np.prod(Xtrain.shape[1:])))
Xtest = Xtest.reshape((len(Xtest), np.prod(Xtest.shape[1:])))

# Dimensión de capas
inputImg = Input(shape = (784,))

edim = 32

# Capa 1
encoded = Dense(edim, activation = 'relu')(inputImg)

# Capa 2
decoded = Dense(784, activation = 'sigmoid')(encoded)

# Reconstrucción
autoencoder = Model(inputImg, decoded)

# Entrenar red neuronal

# Early Stopping
EarlyStopping = EarlyStopping(monitor='val_loss', patience=5)

# Compilar modelo
autoencoder.compile(optimizer = 'adam', loss = 'binary_crossentropy')

# Entrenamiendo de autoenconder
autoencoder.fit(Xtrain, Xtrain, epochs = 50, batch_size = 256, shuffle = True, validation_data = (Xtest, Xtest), callbacks = [EarlyStopping])

# Recontruir imagen
decodedImg = autoencoder.predict(Xtest)

# Grafica
n = 10
plt.figure(figsize = (20, 4))

for i in range(n):
  x = plt.subplot(2, n, i + 1)
  plt.imshow(Xtest[i].reshape(28, 28))
  plt.gray()
  x.get_xaxis().set_visible(False)
  x.get_yaxis().set_visible(False)

  # Imagen recontruida
  x = plt.subplot(2, n, i + 1 + n)
  plt.imshow(Xtest[i].reshape(28, 28))
  plt.gray()
  x.get_xaxis().set_visible(False)
  x.get_yaxis().set_visible(False)

plt.show

# Commented out IPython magic to ensure Python compatibility.
# REDES GENERATIVAS ADVERSARIAS (GANs)

# Instalar la API de Kaggle
!pip install kaggle

# Subir el archivo kaggle.json y configurar los permisos
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

from kaggle.api.kaggle_api_extended import KaggleApi

api = KaggleApi()
api.authenticate()

api.dataset_download_files('jutrera/stanford-car-dataset-by-classes-folder',
                           path='/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/',
                           unzip=True)

import numpy as np # Operaciones numéricas y manejo de arrays.
import pandas as pd # Manipulación y análisis de datos.
import os # Interacción con el sistema operativo.
from pathlib import Path # Manejo de rutas del sistema de archivos.
from PIL import Image # Procesamiento de imágenes.
import glob # Búsqueda de rutas con patrones específicos.
import random # Generación de números aleatorios.

# Data train
path_base = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/'
allfiles = [f for f in glob.glob(path_base + "/**/*.jpg", recursive=True)]
random.shuffle(allfiles)

files = []
for i in range(0, len(allfiles)):
    my_file = Path(allfiles[i])
    if my_file.is_file():
        im = Image.open(my_file)
        image = np.array(im)
        if image.ndim == 3:
            files.append(allfiles[i])
        else:
            print(allfiles[i])

# Repite el proceso para el conjunto de prueba
path_base = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/'
allfiles = [f for f in glob.glob(path_base + "/**/*.jpg", recursive=True)]
random.shuffle(allfiles)

for i in range(0, len(allfiles)):
    my_file = Path(allfiles[i])
    if my_file.is_file():
        im = Image.open(my_file)
        image = np.array(im)
        if image.ndim == 3:
            files.append(allfiles[i])
        else:
            print(allfiles[i])

train_df = np.array(files)
print(train_df.shape)

import numpy as np # Operaciones numéricas y manejo de arrays.
from scipy import misc # Utilidades para procesamiento de imágenes en SciPy.
from PIL import Image, ImageOps # Procesamiento de imágenes y operaciones de edición.
import glob # Búsqueda de rutas con patrones específicos.
import matplotlib.pyplot as plt # Creación de gráficos y visualizaciones.
import scipy.misc # (Deprecado) Utilidades para procesamiento de imágenes en SciPy.
from matplotlib.pyplot import imshow # Visualizar imágenes en Jupyter notebooks.
# %matplotlib inline
# Configuración para mostrar gráficos de matplotlib dentro del Jupyter Notebook.
from IPython.display import SVG # Visualización de imágenes SVG en Jupyter notebooks.
import cv2 # Procesamiento de imágenes y visión por computadora.
import seaborn as sn # Visualización de datos estadísticos.
import pandas as pd # Manipulación y análisis de datos.
import pickle # Serialización y deserialización de objetos en Python.
from pathlib import Path # Manejo de rutas del sistema de archivos.
from keras import layers # Base de las capas para construir modelos de redes neuronales en Keras.
from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout # Capas para construir arquitecturas de modelos.
from keras.layers import Reshape, UpSampling2D, Conv2DTranspose, LeakyReLU # Capas para modelar redes neuronales, incluyendo transformaciones y activaciones.
from keras.models import Sequential, Model, load_model # Herramientas para definir y cargar modelos de Keras.
from keras.preprocessing import image # Utilidades para el procesamiento de imágenes.
from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator # Carga y transforma imágenes para el entrenamiento.
from keras.applications.imagenet_utils import decode_predictions # Decodifica predicciones en ImageNet.
from keras.applications import densenet # Modelo preentrenado DenseNet.
from keras.utils import plot_model # Visualización de la arquitectura de modelos.
from keras.initializers import glorot_uniform # Inicializador de pesos.
from keras import losses # Funciones de pérdida para el entrenamiento de modelos.
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback # Callbacks para el entrenamiento de modelos.
from keras.optimizers import Adam, RMSprop # Optimizadores para el entrenamiento de modelos.
from keras import regularizers # Regularizadores para evitar el sobreajuste.
from keras import backend as K # Funciones de backend, permite escribir código de bajo nivel.
from keras import datasets # Conjuntos de datos para pruebas y entrenamiento.
from sklearn.metrics import confusion_matrix, classification_report # Métricas para evaluar modelos de clasificación.
import tensorflow as tf # Biblioteca de aprendizaje automático y redes neuronales.

# Generamos las variables
latent_dim = 100 # Dimensión del espacio latente para generar datos.
height = 32 # Altura de las imágenes en píxeles.
width = 32 # Anchura de las imágenes en píxeles.
channels = 3 # Número de canales de la imagen, 3 para RGB.
batch_size = 32 # Tamaño del lote para el entrenamiento del modelo.

def build_generator():
  # Construye un generador que toma una entrada del espacio latente y produce una imagen de 32x32x3.
  generator_input = layers.Input(shape=(latent_dim,))

  # Primero, transforma la entrada en un mapa de características de 16x16 con 128 canales
  x = layers.Dense(128 * 16 * 16)(generator_input)
  x = layers.LeakyReLU()(x)
  x = layers.Reshape((16, 16, 128))(x)

  # Luego, añade una capa convolucional
  x = layers.Conv2D(256, 5, padding='same')(x)
  x = layers.LeakyReLU()(x)

  # Hace un upsampling a 32x32
  x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)
  x = layers.LeakyReLU()(x)

  # Algunas capas convolucionales más
  x = layers.Conv2D(256, 5, padding='same')(x)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(256, 5, padding='same')(x)
  x = layers.LeakyReLU()(x)

  # Produce un mapa de características de 32x32 con un canal (para imágenes RGB, serían 3 canales)
  x = layers.Conv2D(channels, 7, padding='same')(x)
  x = layers.LeakyReLU()(x)
  generator = Model(generator_input, x)
  generator.summary()

  return generator

  def build_discriminator():
  # Construye un discriminador que clasifica imágenes de 32x32x3 como reales o falsas.
  discriminator_input = layers.Input(shape=(height, width, channels))
  x = layers.Conv2D(128, 3)(discriminator_input)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(128, 4, strides=2)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(128, 4, strides=2)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Conv2D(128, 4, strides=2)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Flatten()(x)
  # Una capa de dropout - ¡un truco importante!
  x = layers.Dropout(0.4)(x)
  x = layers.Dense(10)(x)
  x = layers.LeakyReLU()(x)
  x = layers.Dropout(0.4)(x)

  # Capa de clasificación
  x = layers.Dense(1)(x)

  discriminator = Model(discriminator_input, x)
  discriminator.summary()

  return discriminator