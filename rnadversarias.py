# -*- coding: utf-8 -*-
"""RNadversarias.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17s6u7kGdHdBx1TdNDG2K4vpe2_jLObbL
"""

# Instalar la API de Kaggle
!pip install kaggle

# Subir el archivo kaggle.json y configurar los permisos
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

from kaggle.api.kaggle_api_extended import KaggleApi

api = KaggleApi()
api.authenticate()

api.dataset_download_files('jutrera/stanford-car-dataset-by-classes-folder',
                           path='/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/',
                           unzip=True)

import numpy as np # Operaciones numéricas y manejo de arrays.
import pandas as pd # Manipulación y análisis de datos.
import os # Interacción con el sistema operativo.
from pathlib import Path # Manejo de rutas del sistema de archivos.
from PIL import Image # Procesamiento de imágenes.
import glob # Búsqueda de rutas con patrones específicos.
import random # Generación de números aleatorios.

# Data train
path_base = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/'
allfiles = [f for f in glob.glob(path_base + "/**/*.jpg", recursive=True)]
random.shuffle(allfiles)

files = []
for i in range(0, len(allfiles)):
    my_file = Path(allfiles[i])
    if my_file.is_file():
        im = Image.open(my_file)
        image = np.array(im)
        if image.ndim == 3:
            files.append(allfiles[i])
        else:
            print(allfiles[i])

# Repite el proceso para el conjunto de prueba
path_base = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/'
allfiles = [f for f in glob.glob(path_base + "/**/*.jpg", recursive=True)]
random.shuffle(allfiles)

for i in range(0, len(allfiles)):
    my_file = Path(allfiles[i])
    if my_file.is_file():
        im = Image.open(my_file)
        image = np.array(im)
        if image.ndim == 3:
            files.append(allfiles[i])
        else:
            print(allfiles[i])

train_df = np.array(files)
print(train_df.shape)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # Operaciones numéricas y manejo de arrays.
from scipy import misc # Utilidades para procesamiento de imágenes en SciPy.
from PIL import Image, ImageOps # Procesamiento de imágenes y operaciones de edición.
import glob # Búsqueda de rutas con patrones específicos.
import matplotlib.pyplot as plt # Creación de gráficos y visualizaciones.
import scipy.misc # (Deprecado) Utilidades para procesamiento de imágenes en SciPy.
from matplotlib.pyplot import imshow # Visualizar imágenes en Jupyter notebooks.
# %matplotlib inline
# Configuración para mostrar gráficos de matplotlib dentro del Jupyter Notebook.
from IPython.display import SVG # Visualización de imágenes SVG en Jupyter notebooks.
import cv2 # Procesamiento de imágenes y visión por computadora.
import seaborn as sn # Visualización de datos estadísticos.
import pandas as pd # Manipulación y análisis de datos.
import pickle # Serialización y deserialización de objetos en Python.
from pathlib import Path # Manejo de rutas del sistema de archivos.
from keras import layers # Base de las capas para construir modelos de redes neuronales en Keras.
from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout # Capas para construir arquitecturas de modelos.
from keras.layers import Reshape, UpSampling2D, Conv2DTranspose, LeakyReLU # Capas para modelar redes neuronales, incluyendo transformaciones y activaciones.
from keras.models import Sequential, Model, load_model # Herramientas para definir y cargar modelos de Keras.
from keras.preprocessing import image # Utilidades para el procesamiento de imágenes.
from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator # Carga y transforma imágenes para el entrenamiento.
from keras.applications.imagenet_utils import decode_predictions # Decodifica predicciones en ImageNet.
from keras.applications import densenet # Modelo preentrenado DenseNet.
from keras.utils import plot_model # Visualización de la arquitectura de modelos.
from keras.initializers import glorot_uniform # Inicializador de pesos.
from keras import losses # Funciones de pérdida para el entrenamiento de modelos.
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback # Callbacks para el entrenamiento de modelos.
from keras.optimizers import Adam, RMSprop # Optimizadores para el entrenamiento de modelos.
from keras import regularizers # Regularizadores para evitar el sobreajuste.
from keras import backend as K # Funciones de backend, permite escribir código de bajo nivel.
from keras import datasets # Conjuntos de datos para pruebas y entrenamiento.
from sklearn.metrics import confusion_matrix, classification_report # Métricas para evaluar modelos de clasificación.

import tensorflow as tf # Biblioteca de aprendizaje automático y redes neuronales.

# Generamos las variables
latent_dim = 100 # Dimensión del espacio latente para generar datos.
height = 32 # Altura de las imágenes en píxeles.
width = 32 # Anchura de las imágenes en píxeles.
channels = 3 # Número de canales de la imagen, 3 para RGB.
batch_size = 32 # Tamaño del lote para el entrenamiento del modelo.

def build_generator():
    # Construye un generador que toma una entrada del espacio latente y produce una imagen de 32x32x3.
    generator_input = layers.Input(shape=(latent_dim,))

    # Primero, transforma la entrada en un mapa de características de 16x16 con 128 canales
    x = layers.Dense(128 * 16 * 16)(generator_input)
    x = layers.LeakyReLU()(x)
    x = layers.Reshape((16, 16, 128))(x)

    # Luego, añade una capa convolucional
    x = layers.Conv2D(256, 5, padding='same')(x)
    x = layers.LeakyReLU()(x)

    # Hace un upsampling a 32x32
    x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)
    x = layers.LeakyReLU()(x)
# Algunas capas convolucionales más
    x = layers.Conv2D(256, 5, padding='same')(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(256, 5, padding='same')(x)
    x = layers.LeakyReLU()(x)

    # Produce un mapa de características de 32x32 con un canal (para imágenes RGB, serían 3 canales)
    x = layers.Conv2D(channels, 7, padding='same')(x)
    x = layers.LeakyReLU()(x)
    generator = Model(generator_input, x)
    generator.summary()

    return generator

def build_discriminator():
    # Construye un discriminador que clasifica imágenes de 32x32x3 como reales o falsas.
    discriminator_input = layers.Input(shape=(height, width, channels))
    x = layers.Conv2D(128, 3)(discriminator_input)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, 4, strides=2)(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, 4, strides=2)(x)
    x = layers.LeakyReLU()(x)
    x = layers.Conv2D(128, 4, strides=2)(x)
    x = layers.LeakyReLU()(x)
    x = layers.Flatten()(x)
# Una capa de dropout - ¡un truco importante!
    x = layers.Dropout(0.4)(x)
    x = layers.Dense(10)(x)
    x = layers.LeakyReLU()(x)
    x = layers.Dropout(0.4)(x)

    # Capa de clasificación
    x = layers.Dense(1)(x)

    discriminator = Model(discriminator_input, x)
    discriminator.summary()

    return discriminator

def build_gan(discriminator, generator):
    # Configura el discriminador para que no sea entrenable dentro de este modelo GAN.
    discriminator.trainable = False

    # Crea una entrada para el GAN que será procesada por el generador.
    gan_input = layers.Input(shape=(latent_dim,))

    # La salida del GAN es el resultado del discriminador al procesar la salida del generador.
    gan_output = discriminator(generator(gan_input))

    # El modelo GAN une el generador y el discriminador.
    gan = Model(gan_input, gan_output)

    return ganb

from tensorflow.keras.optimizers import RMSprop

# Construye el modelo del discriminador.
discriminator = build_discriminator()

# Configura el optimizador RMSprop para el discriminador con un recorte en los valores de los gradientes.
discriminator_optimizer = RMSprop(learning_rate=0.001, clipvalue=1.0)

# Compila el discriminador con la función de pérdida del error cuadrático medio (mse).
discriminator.compile(optimizer=discriminator_optimizer, loss='mse')

# Generamos las imagenes
from pathlib import Path
from PIL import Image, ImageOps

def generate_real(data, index, size):
    # Abre la imagen del índice especificado en el conjunto de datos.
    im = Image.open(data[index])

    # Ajusta la imagen al tamaño dado manteniendo la relación de aspecto y sin distorsión.
    im = ImageOps.fit(im, size, Image.ANTIALIAS)

    # Convierte la imagen a una matriz NumPy y normaliza los valores de los píxeles.
    npimage = np.array(im) / 255.0

    return npimage

def plot_images(save2file=False, fake=True, samples=16, images=None, dpi=80):
    # Define el tamaño de la figura basado en el número de imágenes y la resolución deseada.
    plt.figure(figsize=(samples * width / dpi, samples * height / dpi))

    for i in range(samples):
        # Itera sobre el conjunto de imágenes y las muestra en una grilla.
        plt.subplot(4, 4, i + 1)
        image = images[i, :, :, :]
        image = np.reshape(image, [width, height, channels])
        # Ajusta el rango de los valores de píxeles y los convierte al tipo de datos adecuado.
        plt.imshow((image * 255).astype(np.uint8))
        plt.axis('off')  # Oculta los ejes de las imágenes.

    plt.tight_layout()  # Ajusta el layout para evitar la superposición de imágenes.

    if save2file:
        plt.savefig(filename)  # Guarda la figura en un archivo si se requiere.
        plt.close('all')  # Cierra la figura para liberar memoria.
    else:
        plt.show()  # Muestra la figura en el notebook o script.

def plot_image(image, save2file=False, dpi=80):
    # Define el tamaño de la figura basado en las dimensiones de la imagen y la resolución deseada.
    plt.figure(figsize=(width / dpi, height / dpi))
    # Ajusta la forma de la imagen a su forma original y cambia el rango de los valores de píxeles.
    image = np.reshape(image, [width, height, channels])
    # Muestra la imagen utilizando la representación de píxeles adecuada.
    plt.imshow((image * 255).astype(np.uint8))
    plt.axis('off')  # Oculta los ejes para una mejor visualización de la imagen.
    plt.tight_layout()  # Ajusta el layout para evitar superposiciones o espacios innecesarios.

    if save2file:
        plt.savefig(filename)  # Guarda la imagen en un archivo si se especifica.
        plt.close('all')  # Cierra la figura para liberar memoria.
    else:
        plt.show()  # Muestra la imagen en el notebook o script.

im = generate_real(train_df, 10, (width, height))  # Genera una imagen real a partir del conjunto de datos de entrenamiento.
print(im.dtype)  # Imprime el tipo de dato de los elementos de la imagen.
plot_image(im, False, dpi=10)  # Muestra la imagen generada en pantalla con una baja resolución de puntos por pulgada (dpi).

#Esta secuencia de código produce una imagen real del conjunto de datos de entrenamiento,
# imprime el tipo de datos de la imagen (que se espera que sea un array de float debido a la normalización),
# y luego la muestra utilizando una baja resolución para un posible efecto visual estilizado.

generated_images = generator.predict(np.random.normal(size=(batch_size, latent_dim)))  # Genera imágenes usando el modelo del generador a partir de ruido aleatorio.
plot_images(save2file=False, fake=True, samples=12, images=generated_images, dpi=60)  # Muestra 12 imágenes falsas generadas en pantalla con una resolución específica.

#. Este fragmento de código utiliza el modelo del generador para crear un conjunto de imágenes a partir de vectores de ruido
#  aleatorio y luego visualiza 12 de estas imágenes generadas con una resolución de 60 DPI (puntos por pulgada).
#  Las imágenes son identificadas como falsas o generadas por la red.

iterations = 5000

start = 0
for step in range(iterations):
    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))
    generated_images = generator.predict(random_latent_vectors)
    stop = start + batch_size
    real_images = np.zeros((batch_size, width, height, channels), dtype=np.float64)

    cont = 0
    for k in range(start, stop):
        real_images[cont] = generate_real(train_df, k, (width, height));
        cont += 1

    labels_real = np.ones((batch_size, 1))
    labels_fake = np.ones((batch_size, 1))

# Add random noise to the labels - important trick!
    labels_real += 0.05 * np.random.random(labels_real.shape)
    labels_fake += 0.05 * np.random.random(labels_fake.shape)

    # Train the discriminator
    d_loss1 = discriminator.train_on_batch(real_images, labels_real)
    d_loss2 = discriminator.train_on_batch(generated_images, -labels_fake)
    d_loss = 0.5 * (d_loss1 + d_loss2)

    # sample random points in the latent space
    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))

    # Assemble labels that say "all real images"
    misleading_targets = np.ones((batch_size, 1))

# Train the generator (via the gan model,
    # where the discriminator weights are frozen)
    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)

    start += batch_size
    if start > len(train_df) - batch_size:
        start = 0

    if step % 100 == 0:
        print('discriminator loss at step %s:\t %s \t-- adversarial loss at step %s:\t %s' % (step, d_loss, step, a_loss))

    # Occasionally save / plot
    if step % 500 == 0:
        showimages = np.concatenate([real_images[:4], generated_images[:8]])
        plot_images(save2file=False, fake=True, samples=12, images=showimages, dpi=60)