# -*- coding: utf-8 -*-
"""RNcovulucionalesTareaPt2(aves).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JIxasZQqlhUugd7bh7sDnX6wvcfQG6V1
"""

from google.colab import files
uploaded = files.upload()

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# De la url del dataset se obtiene el nombre del programador y el nombre del dataset "gpiosenka/100-bird-species"
!kaggle datasets download -d gpiosenka/100-bird-species

# Descomprimir el archivo
!unzip 100-bird-species.zip

import matplotlib.pyplot as plt
from PIL import Image

# Obtener las imagenes
imgRoute = '/content/train/ALBATROSS/001.jpg'

# Abrir imagen
img = Image.open(imgRoute)

# Mostrar imagen
plt.imshow(img)
plt.axis('off')
plt.show()

!ls /content/train/ALBATROSS | head -5

# Graficar las imagenes
imgs5 = [
  '001.jpg',
  '002.jpg',
  '003.jpg',
  '004.jpg',
  '005.jpg'
]
plt.figure(figsize = (15, 3))

for i, img5 in enumerate(imgs5):
  imgRoute = f'/content/train/ALBATROSS/{img5}'
  img = Image.open(imgRoute)

  # Configuración de subplot
  plt.subplot(1, 5, i + 1)
  plt.imshow(img)
  plt.axis("off")
  plt.title(img5)

plt.tight_layout()
plt.show()

# Crear red neuronal
import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
import random

# Definición de directorios a cada carpeta de data
main = '/content/test'
bird1 = '/content/test/ABBOTTS BABBLER'
bird2 = '/content/test/ABBOTTS BOOBY'
bird3 = '/content/test/ABYSSINIAN GROUND HORNBILL'

# Arquitectura de la red
data = []
talla = 100
categorias = ['ABBOTTS BABBLER', 'ABBOTTS BOOBY', 'ABYSSINIAN GROUND HORNBILL']

for categoria in categorias:
  folder = os.path.join(main, categoria)
  label = categorias.index(categoria)

  for imagen in os.listdir(folder):

    #Excepto archivos gift
    if imagen.endswith('.gif'):
      continue

    imgPath = os.path.join(folder, imagen)
    imgArray = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)

  # Redimensionar la imagen
    try:
      imgArray = cv2.resize(imgArray, (talla, talla))
      data.append([imgArray, label])

    except Exception as e:
      print(e)

# Separar imagenes y etiquetas

xTrain = []
yTrain = []

for imgs, labels in data:
  xTrain.append(imgs)
  yTrain.append(labels)

# Normalizar los datos
xTrain = np.array(xTrain).reshape(-1, talla, talla, 1) / 255.0
yTrain = np.array(yTrain)

len(data)

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(xTrain, yTrain, test_size = 0.20, random_state = 0)

# Red neuronal
from keras.models import Sequential
from keras.layers import Dense, Flatten, LeakyReLU
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping

# Modelo
modelo = Sequential()

# Capa de entrada
modelo.add(Flatten(input_shape = (talla, talla, 1)))

# 1° capa oculta
modelo.add(Dense(256, activation = 'relu'))

# 2° capa oculpa
modelo.add(Dense(128, activation = 'swish'))

# 3° capa oculpa
modelo.add(Dense(64))
modelo.add(LeakyReLU(alpha = 0.01))

# Capa de salida
modelo.add(Dense(len(categorias), activation = 'softmax'))

# Compilar el modelo
modelo.compile(optimizer = Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# Early stoppings
earlyStop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)

# Entrenamiento
history = modelo.fit(xTrain, yTrain, epochs = 50, validation_data = (xTest, yTest), callbacks = [earlyStop], batch_size = 32)